# Default values for quickwit.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: quickwit/quickwit
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  # tag: v0.4.0

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext:
  fsGroup: 1005

securityContext:
  runAsNonRoot: true
  runAsUser: 1005

# Additional global env
environment:
  QW_METASTORE_URI: s3://quickwit/indexes
  # KEY: VALUE

searcher:
  replicaCount: 1

  # Extra env for searcher
  extraEnv:
    {}
    # KEY: VALUE

  resources:
    {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  ## Pod distruption budget
  podDisruptionBudget:
    {}
    # maxUnavailable: 1
    # minAvailable: 2

  persistentVolume:
    enabled: false
    # storage: "1Gi"
    # storageClass: ""

  updateStrategy:
    {}
    # type: RollingUpdate

  startupProbe:
    httpGet:
      path: /health/livez
      port: rest
    failureThreshold: 12
    periodSeconds: 5

  livenessProbe:
    httpGet:
      path: /health/livez
      port: rest

  readinessProbe:
    httpGet:
      path: /health/readyz
      port: rest

  nodeSelector: {}

  tolerations: []

  affinity: {}

indexer:
  replicaCount: 1

  # Extra env for indexer
  extraEnv:
    {}
    # KEY: VALUE

  resources:
    {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  ## Pod distruption budget
  podDisruptionBudget:
    {}
    # maxUnavailable: 1
    # minAvailable: 2

  updateStrategy:
    {}
    # type: RollingUpdate

  startupProbe:
    httpGet:
      path: /health/livez
      port: rest
    failureThreshold: 12
    periodSeconds: 5

  livenessProbe:
    httpGet:
      path: /health/livez
      port: rest

  readinessProbe:
    httpGet:
      path: /health/readyz
      port: rest

  nodeSelector: {}

  tolerations: []

  affinity: {}

  persistentVolume:
    enabled: false
    storage: "10Gi"
    storageClass: "longhorn"

metastore:
  replicaCount: 1

  # Extra env for metastore
  extraEnv:
    {}
    # KEY: VALUE

  resources:
    {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  ## Pod distruption budget
  podDisruptionBudget:
    {}
    # maxUnavailable: 1
    # minAvailable: 2

  updateStrategy:
    {}
    # type: RollingUpdate

  startupProbe:
    httpGet:
      path: /health/livez
      port: rest
    failureThreshold: 12
    periodSeconds: 5

  livenessProbe:
    httpGet:
      path: /health/livez
      port: rest

  readinessProbe:
    httpGet:
      path: /health/readyz
      port: rest

  nodeSelector: {}

  tolerations: []

  affinity: {}

janitor:
  # Enable Janitor service
  enabled: true

  # Extra env for searcher
  extraEnv:
    {}
    # KEY: VALUE

  resources:
    {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  ## Pod distruption budget
  podDisruptionBudget:
    {}
    # maxUnavailable: 1
    # minAvailable: 2

  updateStrategy:
    {}
    # type: RollingUpdate

  startupProbe:
    httpGet:
      path: /health/livez
      port: rest
    failureThreshold: 12
    periodSeconds: 5

  livenessProbe:
    httpGet:
      path: /health/livez
      port: rest

  readinessProbe:
    httpGet:
      path: /health/readyz
      port: rest

  nodeSelector: {}

  tolerations: []

  affinity: {}

# Deploy jobs to bootstrap creation of indexes and sources for quickwit clusters
bootstrap:
  # Enable boostrap jobs
  enabled: false

  # Extra env for boostrap jobs
  extraEnv:
    {}
    # KEY: VALUE

  resources:
    {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

# Quickwit configuration
config:
  # Metastore configuration.
  postgres: {}
  #   host: ""
  #   port: 5432
  #   database: metastore
  #   username: quickwit
  #   password: ""
  storage:
    s3:
      endpoint: "http://garage.garage.svc.cluster.local:3900"
      flavor: garage
      region: garage
      access_key_id: "GK4cc5e3d78eb2a8a804e02429"
      secret_access_key: "your-admin-key"

  default_index_root_uri: s3://quickwit/indexes
  # Indexer settings
  # indexer:
  #   split_store_max_num_bytes: 200G
  #   split_store_max_num_splits: 10000
  # Searcher settings
  # searcher:
  #   fast_field_cache_capacity: 10G
  #   split_footer_cache_capacity: 1G
  #   max_num_concurrent_split_streams: 100

  indexes:
    []
    # - version: 0.4
    #   index_id: my-index
    #   doc_mapping:
    #     field_mappings:
    #       - name: timestamp
    #         type: datetime
    #         fast: true
    #         input_formats:
    #           - unix_timestamp
    #         output_format: unix_timestamp_secs
    #       - name: body
    #         type: text
    #     timestamp_field: timestamp
    #   search_settings:
    #     default_search_fields: [body]
    #   indexing_settings:
    #     merge_policy:
    #       type: limit_merge
    #       max_merge_ops: 3
    #       merge_factor: 10
    #       max_merge_factor: 12

  sources:
    []
    # - index: my-index
    #   source:
    #     version: 0.4
    #     source_id: my-source
    #     source_type: kafka
    #     num_pipelines: 1
    #     params:
    #       topic: quickwit-topic
    #       client_params:
    #         bootstrap.servers: kafka-server-endpoint1:9092,kafka-server-endpoint2:9092

# Prometheus metrics
serviceMonitor:
  enabled: false
  interval: 60s
  scrapeTimeout: 10s
  metricRelabelings: []
  #  - action: replace
  #    regex: quickwit-(.*)
  #    replacement: $1
  #    sourceLabels: [cluster]
  #    targetLabel: qw_cluster
  #  - action: labeldrop
  #    regex: (endpoint|cluster)
  relabelings: []
  #  - sourceLabels: [__meta_kubernetes_pod_node_name]
  #    targetLabel: instance

# Prometheus Operator alertmanager alerts
prometheusRule:
  enabled: false
  rules: []
  #  - alert: Example
  #    expr: metric == 1
  #    for: 1m
  #    labels:
  #      severity: warning

service:
  type: ClusterIP

ingress:
  enabled: false
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    external-dns.alpha.kubernetes.io/hostname: qw.kubetailor.io
    external-dns.alpha.kubernetes.io/target: lb.kubetailor.io
    external-dns.alpha.kubernetes.io/cloudflare-proxied: "false"
    external-dns.alpha.kubernetes.io/ttl: "60"
    kubernetes.io/tls-acme: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
  hosts:
    - host: qw.kubetailor.io
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls:
    - secretName: quickwit-tls
      hosts:
        - qw.kubetailor.io

resources:
  {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
